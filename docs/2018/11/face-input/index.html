<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow">
    <meta name="description" content="Mapear emociones a través de pictogramas como método de entrada de datos en el contexto de la creación de interfaces digitales ¿Es más claro ingresar una emoción o un número?">
    <meta name="author" content="Herbert Spencer">
    <meta name="copyright" content="(cc) Todos los contenidos bajo Creative Commons BY 4.0">
    <title>HTML input: Pictograma · {dp} · doble página</title>

    <!-- Open Graph / Facebook -->
    <meta property="og:site_name" content="{dp} · doble página">
    <meta property="og:title" content="HTML input: Pictograma">
    <meta property="og:description" content="Mapear emociones a través de pictogramas como método de entrada de datos en el contexto de la creación de interfaces digitales ¿Es más claro ingresar una emoción o un número?">
    <meta property="og:type" content="article">
    <meta property="og:url" content="http://0.0.0.0:4000/2018/11/face-input/">
    <meta property="og:image" content="http://0.0.0.0:4000/android-chrome-512x512.png">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="HTML input: Pictograma">
    <meta name="twitter:description" content="Mapear emociones a través de pictogramas como método de entrada de datos en el contexto de la creación de interfaces digitales ¿Es más claro ingresar una emoción o un número?">
    <meta name="twitter:image" content="http://0.0.0.0:4000/android-chrome-512x512.png">
  
    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/style.css">
  
    <!-- Feed -->
    <link rel="alternate" type="application/atom+xml" title="Feed de Posts" href="/feed.xml">

    
  
    <!-- Favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

  </head>
  
<body>
  <header>
    <div class="navbar">
        <h1 id="title"><a href="/">{dp} · doble página</a></h1>
        
        
<form id="search-form" action="#" method="get" class="search-form">
    <input type="text" name="query" id="search-input" placeholder="Search..." aria-label="Buscar" autocomplete="off">
    <button type="submit" aria-label="Submit Search" class="search-button">
      <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="svg-inline--fa fa-search fa-w-16 fa-fw">
        <path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 352c-79.5 0-144-64.5-144-144s64.5-144 144-144 144 64.5 144 144-64.5 144-144 144z"></path>
      </svg>
    </button>
</form>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    const searchForm = document.getElementById("search-form");
    const searchInput = document.getElementById("search-input");
    const articleElement = document.querySelector("article");
    const searchResultsTempDisplay = document.getElementById("search-results-temp-display");

    let originalArticleContent = '';
    let searchIndex = [];

    // --- Lógica para el placeholder multilingüe ---
    function setPlaceholderByLanguage() {
      const userLang = navigator.language || navigator.userLanguage;
      let placeholderText = "Search..."; // Placeholder por defecto (inglés)

      if (userLang.startsWith('es')) {
        placeholderText = "Buscar: cmd + B"; 
      } else if (userLang.startsWith('en')) {
        placeholderText = "Search: cmd + B";
      } else if (userLang.startsWith('de')) {
        placeholderText = "Suchen: cmd + B";
      }
      // Añade más idiomas aquí según sea necesario

      searchInput.setAttribute('placeholder', placeholderText);
      searchInput.setAttribute('aria-label', placeholderText); 
    }

    setPlaceholderByLanguage(); // Llama a la función para establecer el placeholder inicial


    // Cargar el índice de búsqueda (feed.json)
    fetch("/feed.json")
      .then(response => response.json())
      .then(data => {
        searchIndex = data;
        console.log("Índice de búsqueda cargado desde feed.json:", searchIndex);
      })
      .catch(error => {
        console.error("Error al cargar el índice de búsqueda desde feed.json:", error);
        searchResultsTempDisplay.innerHTML = "<p class='no-results-message'>Error al cargar el buscador. Intente de nuevo más tarde.</p>";
      });

    // Atajo de teclado para enfocar el input de búsqueda (Ctrl + . o Cmd + .)
    document.addEventListener('keydown', function (e) {
      if ((e.ctrlKey || e.metaKey) && ((e.key === 'b') || (e.key === 'B'))) {
        e.preventDefault();
        searchInput.focus();
      }
    });

    function displayResultsInArticle(results) {
      if (originalArticleContent === '') {
        originalArticleContent = articleElement.innerHTML;
      }

      articleElement.innerHTML = '';

      if (results.length > 0) {
        const resultsList = document.createElement("ul");
        resultsList.className = "search-results-list";
        results.forEach(item => {
          const listItem = document.createElement("li");
          const formattedDate = new Date(item.fecha).toLocaleDateString(navigator.language || navigator.userLanguage, { year: 'numeric', month: 'long', day: 'numeric' });
          listItem.innerHTML = `
            <a href="${item.url}" class="result-link">
              <h3 class="result-title">${item.titulo}</h3>
            <p class="result-excerpt">${item.contenido.substring(0, 200)}...</p>
            <small class="result-meta">${formattedDate} ${item.categorias && item.categorias.length > 0 ? ' | Categorías: ' + item.categorias.join(', ') : ''} ${item.etiquetas && item.etiquetas.length > 0 ? ' | Etiquetas: ' + item.etiquetas.join(', ') : ''}</small>
            </a>
          `;
          resultsList.appendChild(listItem);
        });
        articleElement.appendChild(resultsList);
      } else {
        articleElement.innerHTML = '<p class="no-results-message">No se encontraron resultados para su búsqueda.</p>';
      }
    }

    searchForm.addEventListener("submit", function (e) {
      e.preventDefault();
      performSearch();
    });

    searchInput.addEventListener("input", function() {
        if (searchInput.value.length >= 2 || searchInput.value.length === 0) {
            performSearch();
        }
    });

    function performSearch() {
        const query = searchInput.value.toLowerCase().trim();

        if (query.length === 0) {
            if (originalArticleContent !== '') {
              articleElement.innerHTML = originalArticleContent;
            }
            return;
        }

        const filteredResults = searchIndex.filter(item => {
            const titleMatches = item.titulo && item.titulo.toLowerCase().includes(query);
            const contentMatches = item.contenido && item.contenido.toLowerCase().includes(query);
            const categoriesMatches = Array.isArray(item.categorias) && item.categorias.some(cat => cat.toLowerCase().includes(query));
            const tagsMatches = Array.isArray(item.etiquetas) && item.etiquetas.some(tag => tag.toLowerCase().includes(query));
            
            return titleMatches || contentMatches || categoriesMatches || tagsMatches;
        });

        displayResultsInArticle(filteredResults);
    }

    document.addEventListener('click', function(event) {
        if (!searchForm.contains(event.target) && searchInput.value.length === 0 && originalArticleContent !== '' && articleElement.innerHTML !== originalArticleContent) {
            articleElement.innerHTML = originalArticleContent;
        }
    });

    searchInput.addEventListener('focusout', function() {
        if (searchInput.value.length === 0 && originalArticleContent !== '' && articleElement.innerHTML !== originalArticleContent) {
            articleElement.innerHTML = originalArticleContent;
        }
    });
  });
</script>
        
        <!-- Botón toggle -->
        <a href="#" id="toggle-nav" aria-expanded="false">[+]</a>
    </div>
    <nav id="main" hidden>
      <ul>
        
        
          <li>
            <a class="nav-link" href="/about/herbert-spencer/">Acerca del autor</a>
          </li>
        
          <li>
            <a class="nav-link" href="/about/doble-pagina/">doble página · {dp}</a>
          </li>
        
      </ul>
    </nav>
    <!-- Script de toggle -->
    <script>
      document.addEventListener("DOMContentLoaded", function () {
        const btn = document.getElementById("toggle-nav");
        const nav = document.getElementById("main");
        btn.addEventListener("click", function (e) {
          e.preventDefault();
          const isHidden = nav.hasAttribute("hidden");
          nav.toggleAttribute("hidden");
          btn.textContent = isHidden ? "[–]" : "[+]";
          btn.setAttribute("aria-expanded", isHidden);
        });
      });
    </script>
 </header>

  <main id="dp">
    <sidebar>
      <h1 class="title">HTML input: Pictograma</h1>

      <!-- Imagen (si image.path existe y no tiene sidebar: false) -->
      
        <figure>
          <img
            src="/assets/uploads/2018/11/faces.png"
            alt=""
            class=""
            style=""
          />
        </figure>
      

      <!-- Fecha --><time datetime="2018-11-11T17:15:05-03:00">
        11 de noviembre de 2018
      </time>

      <!-- P5 (si p5.script existe y no tiene sidebar: false) -->
      

      <!-- Vimeo (si vimeo.url existe y no tiene sidebar: false) -->
      

      <!-- YouTube (si youtube.url existe y no tiene sidebar: false) -->
      

      <!-- Bloque de sidebar en HTML directo -->
      

      <!-- Bloque de sidebar en MD (convertido a HTML) -->
      

      <!-- Posts Relacionados -->
      <div class="related-posts">
      <h4>Artículos relacionados</h4>
      <ul><li>
            <a href="/2025/02/prologo-para-pictonet/">Prólogo para PictoNet</a><span class="tag">pictogramas</span></li><li>
            <a href="/2008/02/para-que-investigamos-con-usuarios/">Para qué investigamos con usuarios</a><span class="tag">research</span></li><li>
            <a href="/2008/03/historias-dirigidas/">Historias Dirigidas: Interpretando Experiencias</a><span class="tag">research</span></li><li>
            <a href="/2010/09/herramienta-y-espacio/">Herramienta y Espacio</a><span class="tag">interacción</span></li><li>
            <a href="/2017/02/tecnica-y-diseno/">Técnica y Diseño</a><span class="tag">interacción</span><span class="tag">interfaz</span></li></ul>
    </div>

      <!-- Link a la cita -->
      <a id="btn-citar-face-input" class="btn-citar">&#x301E;</a>
  
  <div id="modal-citar-face-input" class="modal-citar">
    <div class="modal-contenido">
      <span class="modal-cerrar">&times;</span>
      <h3>Referencias</h3>
  
      <h4>APA (7ª edición)</h4>
      <p id="apa-cita">
        Spencer, H. (2018, November 11). <em>HTML input: Pictograma</em>. 
        En <em>{dp} · doble página</em>. https://herbertspencer.net/2018/11/face-input/. Visitado en: <span class="fecha-acceso"></span>
      </p>
  
      <h4>MLA</h4>
      <p id="mla-cita">
        Spencer, Herbert. "<em>HTML input: Pictograma</em>." <em>{dp} · doble página</em>, 11 November 2018, 
        https://herbertspencer.net/2018/11/face-input/. Accedido el <span class="fecha-acceso"></span>.
      </p>
  
      <h4>Chicago</h4>
      <p id="chicago-cita">
        Spencer, Herbert. "<em>HTML input: Pictograma</em>." {dp} · doble página. Publicado el 11 de November de 2018. 
        https://herbertspencer.net/2018/11/face-input/. Consultado el <span class="fecha-acceso"></span>.
      </p>
    </div>
  </div>
  
  <script>
  document.addEventListener("DOMContentLoaded", function () {
    const btn = document.getElementById("btn-citar-face-input");
    const modal = document.getElementById("modal-citar-face-input");
    const cerrar = modal.querySelector(".modal-cerrar");
  
    btn.addEventListener("click", () => modal.style.display = "block");
    cerrar.addEventListener("click", () => modal.style.display = "none");
    window.addEventListener("click", e => {
      if (e.target == modal) modal.style.display = "none";
    });
  
    // Insertar fecha de acceso en formato: 26 de marzo de 2025
    const fecha = new Date();
    const meses = [
      "enero", "febrero", "marzo", "abril", "mayo", "junio",
      "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"
    ];
    const fechaFormateada = `${fecha.getDate()} de ${meses[fecha.getMonth()]} de ${fecha.getFullYear()}`;
    document.querySelectorAll(".fecha-acceso").forEach(el => el.textContent = fechaFormateada);
  });
  </script>
    </sidebar>

    <article>
      <h3 id="hipótesis-mapear-emociones-a-través-de-pictogramas-como-método-de-entrada-de-datos">Hipótesis: Mapear emociones a través de pictogramas como método de entrada de datos</h3>

<p>En el ámbito de la <a href="http://accesibilidad-inclusion.cl">investigación inclusiva</a> y el <a href="https://dl.acm.org/doi/10.1145/3385010.3385023">trabajo con personas con discapacidad intelectual</a>, nuestro equipo ha desarrollado herramientas específicas para la recolección de datos. Estos instrumentos deben ser concebidos desde su origen bajo principios de accesibilidad cognitiva, integrando la accesibilidad como un componente esencial de su diseño.</p>

<p>Planteamos la hipótesis de que el uso de pictogramas faciales para representar emociones podría constituir un mecanismo accesible y eficaz para la entrada de datos en contextos donde la comunicación simbólica convencional presenta barreras. La expresión facial es una de las formas primarias de comunicación interpersonal, y los seres humanos estamos especialmente capacitados para interpretarlas. Nuestras habilidades para leer rostros y detectar sutilezas expresivas han sido fundamentales para establecer alineaciones cognitivas en contextos sociales, permitiendo anticipar intenciones, emociones y respuestas.</p>

<p>Esta idea se fundamenta en la teoría semiótica cognitiva desarrollada por Line Brandt en <em>The Communicative Mind</em>, donde se plantea que la comunicación no es simplemente un intercambio de señales, sino un proceso mental y social en el que dos o más mentes se alinean temporalmente en una escena compartida de significación. Esta “mente comunicativa” emerge de la coordinación dinámica entre expresiones (lo que se manifiesta en un cuerpo) y comprensiones (lo que se configura en una mente), en un contexto determinado. En este sentido, las expresiones faciales cumplen una función de alto nivel, ya que condensan información emocional compleja en patrones reconocibles que operan como “anclas” para la interpretación situacional<sup id="fnref:1"><a href="#fn:1" class="footnote-ref">1</a></sup>.</p>

<div id="canvasContainer"></div>
<div id="qualification">
  <div id="val" style="font-family: Barlow; font-size: 4rem"></div>
</div>
<div id="p5" class="p5-sketch-container" style="text-align: center;">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.11.1/p5.js"></script>

  <p><!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.11.1/addons/p5.sound.min.js"></script> -->
  <script src="/assets/p5/face-input.js"></script></p>

</div>

<h3 id="desarrollo-de-herramientas-face-input-face-qualify-y-face-edit">Desarrollo de Herramientas: Face Input, Face Qualify y Face Edit</h3>

<p>Basándonos en esta hipótesis, desarrollamos una serie de herramientas destinadas a facilitar la entrada y edición de datos emocionales mediante pictogramas faciales:</p>

<ul>
  <li>
    <p><strong><a href="https://github.com/hspencer/face-input"><code class="language-plaintext highlighter-rouge">face-input</code></a></strong>: Una biblioteca JavaScript que permite la creación de entradas basadas en expresiones faciales, funcionando como un control deslizante que representa una gama de emociones. Primer prototipo.</p>
  </li>
  <li>
    <p><strong><a href="https://github.com/hspencer/face-qualify"><code class="language-plaintext highlighter-rouge">face-qualify</code></a></strong>: Una biblioteca complementaria que ofrece una interfaz sencilla para que los usuarios califiquen elementos utilizando expresiones faciales en una escala de cinco niveles escalonados.</p>
  </li>
  <li>
    <p><strong><a href="https://github.com/hspencer/face-edit"><code class="language-plaintext highlighter-rouge">face-edit</code></a></strong>: Una herramienta desarrollada con P5.js para editar y definir nuevas expresiones faciales, permitiendo la personalización de pictogramas utilizados en las herramientas anteriores para su interpolación<sup id="fnref:2"><a href="#fn:2" class="footnote-ref">2</a></sup> .</p>
  </li>
</ul>

<h3 id="validación-y-resultados">Validación y Resultados</h3>

<p>Durante una validación preliminar realizada con el grupo asesor del proyecto, nos enfocamos en las expresiones faciales utilizadas como elementos de entrada, específicamente en los pictogramas de la familia <a href="https://eadpucv.github.io/pixograms/">Pixograms</a>, empleados también en las Partituras de Interacción PiX. Observamos una divergencia sustancial en la interpretación de las expresiones emocionales. Algunas expresiones que, desde una perspectiva de diseño convencional, habíamos clasificado como “positivas” (por ejemplo, una sonrisa amplia con ojos semicerrados y cejas levantadas) fueron interpretadas como sarcasmo, incredulidad o incluso incomodidad por algunos participantes. Del mismo modo, rostros considerados “neutros” o “negativos” fueron asociados con calma o concentración, dependiendo del contexto subjetivo de cada individuo.</p>

<p>Este resultado subraya la complejidad de la interpretación emocional cuando se utilizan patrones visuales estandarizados. La hipótesis inicial, aunque plausible desde un enfoque semiótico y empático, no fue confirmada en la práctica. En su lugar, una escala numérica acompañada de leyendas en lectura fácil resultó ser más clara, permitiendo recoger datos de forma consistente y comprensible para los participantes. La lectura fácil, al estructurar la información de manera explícita, reduce la ambigüedad semántica y facilita la alineación entre la intención del emisor (en este caso, el instrumento de recolección de datos) y la comprensión del receptor.</p>

<h3 id="reflexiones-y-futuras-direcciones">Reflexiones y Futuras Direcciones</h3>

<p>Aunque este resultado no invalida la idea de utilizar pictogramas faciales como canal expresivo, sí destaca la necesidad de incorporar una fase más robusta de codiseño, especialmente en la elección y validación de las expresiones utilizadas. La cognición no es un proceso automático de decodificación, sino una construcción contextual e intersubjetiva. En consecuencia, el diseño de interfaces accesibles debe considerar tanto la legibilidad formal de los símbolos como también su interpretabilidad cultural, afectiva y situacional.</p>

<p>Desde estas humildes herramientas ha quedado claro que cualquier propuesta que busque trabajar con emociones como entrada de datos debe estar sustentada en una comprensión profunda de los procesos comunicativos. Más que en su dimensión técnica o perceptual, en su dimensión intersubjetiva y cultural.</p>

<div class="footnotes">
  <hr />

  <ol>
<li id="fn:1">Brandt, L. (2013). <em>The Communicative Mind: A Linguistic Exploration of Conceptual Integration and Meaning Construction</em>. Cambridge Scholars Publishing. <a href="#fnref:1" class="footnote-back">↩</a></li>
<li id="fn:2">Acá surgió la idea, un poco más complejo y por lo tanto menos accesible, de mensar inputs bidimensionales, siguiendo 2 ejes en la línea de lo que nos muestra Edward Tufte en este gráfico: <br /><br /><img src="/assets/uploads/2018/11/tufte-wolf.png" alt="" /> <a href="#fnref:2" class="footnote-back">↩</a></li>
</ol>
</div>

      <script src="https://utteranc.es/client.js"
        repo="hspencer/hspencer.github.io"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
    </article>
  </main>
  <footer>
   <p>
     <a href="/about/doble-pagina">{doble página}</a> es el sitio personal de 
     <a href="/about/herbert-spencer">Herbert Spencer</a>, iniciado en 2003.  
     Los contenidos están bajo licencia 
     <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="license noopener">CC BY-SA 4.0</a>.  
   </p>
   <p>
     El sitio está generado con <a href="https://jekyllrb.com/" target="_blank" rel="noopener">Jekyll</a>, 
     el código fuente está en <a href="https://github.com/hspencer/dp" target="_blank" rel="noopener">GitHub</a>, 
     y los comentarios están habilitados vía <a href="https://utteranc.es/" target="_blank" rel="noopener">utterances</a>.
   </p>
   <p>
     Última actualización: 24 May 2025 - <a href="/feed.xml">Feed RSS</a>.
   </p>
 </footer>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ML0YZPJS32"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-ML0YZPJS32');
</script>
</body>
</html>